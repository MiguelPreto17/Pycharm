{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3f0952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Start date           Stop date  Duration (min)  \\\n",
      "31   2024-02-25 10:20:00 2024-02-25 10:37:00          16.500   \n",
      "35   2024-02-23 08:37:00 2024-02-23 11:31:00         174.000   \n",
      "52   2024-02-20 14:12:00 2024-02-20 20:23:00         370.850   \n",
      "61   2024-02-19 08:31:00 2024-02-19 11:39:00         188.083   \n",
      "91   2024-02-11 10:48:00 2024-02-11 11:14:00          25.983   \n",
      "...                  ...                 ...             ...   \n",
      "1536 2023-04-03 08:39:00 2023-04-03 13:38:00         298.967   \n",
      "1542 2023-03-31 08:48:00 2023-03-31 13:36:00         288.500   \n",
      "1545 2023-03-31 08:41:00 2023-03-31 10:26:00         105.350   \n",
      "1548 2023-03-31 08:37:00 2023-03-31 08:45:00           8.283   \n",
      "1559 2023-03-29 08:35:00 2023-03-29 10:26:00         111.117   \n",
      "\n",
      "      Total Energy (kWh) Nº cartão EVIO  Weekday  \n",
      "31                 28.52              0        7  \n",
      "35                 31.10              0        5  \n",
      "52                 27.23              0        2  \n",
      "61                 35.26              0        1  \n",
      "91                 22.06              0        7  \n",
      "...                  ...            ...      ...  \n",
      "1536               43.80              0        1  \n",
      "1542               48.17              0        5  \n",
      "1545               12.26              0        5  \n",
      "1548                1.23              0        5  \n",
      "1559               12.60              0        3  \n",
      "\n",
      "[122 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Carregar o dataframe inicial\n",
    "User = pd.read_excel('EVIO_history_01-02-2023_29-02-2024.xlsx')\n",
    "User = User[['Start date','Stop date','Duration (min)', 'Total Energy (kWh)', 'Nº cartão EVIO']]\n",
    "\n",
    "# Remover valores de carregamento de energia inferiores a 1 kWh\n",
    "User = User[User['Total Energy (kWh)'] >= 1]\n",
    "\n",
    "# Remover valores de duração de carregamento inferiores a 5 minutos\n",
    "User = User[User['Duration (min)'] >= 5]\n",
    "\n",
    "User = User[User['Nº cartão EVIO'] == 0]\n",
    "\n",
    "# Convertendo as colunas de data para o formato de data especificado\n",
    "User['Start date'] = pd.to_datetime(User['Start date'], format='%m/%d/%Y | %H:%M')\n",
    "User['Stop date'] = pd.to_datetime(User['Stop date'], format='%m/%d/%Y | %H:%M')\n",
    "\n",
    "# Criando uma nova coluna 'Weekday' que contém o dia da semana\n",
    "User['Weekday'] = User['Start date'].dt.day_name()\n",
    "\n",
    "print(User)\n",
    "\n",
    "weekday_mapping = {\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "\n",
    "User['Weekday'] = User['Weekday'].map(weekday_mapping)\n",
    "\n",
    "print(User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e82972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Start date  Stop date  Duration (min)  Total Energy (kWh)  Nº cartão EVIO  \\\n",
      "0   2023-03-29 2023-03-29         111.117               12.60               0   \n",
      "1   2023-03-30 2023-03-30           0.000                0.00               0   \n",
      "2   2023-03-31 2023-03-31         288.500               48.17               0   \n",
      "3   2023-03-31 2023-03-31         105.350               12.26               0   \n",
      "4   2023-03-31 2023-03-31           8.283                1.23               0   \n",
      "..         ...        ...             ...                 ...             ...   \n",
      "339 2024-02-21 2024-02-21           0.000                0.00               0   \n",
      "340 2024-02-22 2024-02-22           0.000                0.00               0   \n",
      "341 2024-02-23 2024-02-23         174.000               31.10               0   \n",
      "342 2024-02-24 2024-02-24           0.000                0.00               0   \n",
      "343 2024-02-25 2024-02-25          16.500               28.52               0   \n",
      "\n",
      "     Weekday  \n",
      "0          3  \n",
      "1          4  \n",
      "2          5  \n",
      "3          5  \n",
      "4          5  \n",
      "..       ...  \n",
      "339        3  \n",
      "340        4  \n",
      "341        5  \n",
      "342        6  \n",
      "343        7  \n",
      "\n",
      "[344 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Converter colunas de datas para datetime\n",
    "User['Start date'] = pd.to_datetime(User['Start date'])\n",
    "User['Stop date'] = pd.to_datetime(User['Stop date'])\n",
    "\n",
    "# Truncar as datas para terem apenas a informação de data, sem hora\n",
    "#User['Start date'] = User['Start date'].dt.date\n",
    "#User['Stop date'] = User['Stop date'].dt.date\n",
    "\n",
    "# Definir intervalo de datas\n",
    "start_date = User['Start date'].min()\n",
    "end_date = User['Start date'].max()\n",
    "\n",
    "# Gerar todas as datas no intervalo\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Criar DataFrame com todas as datas\n",
    "all_dates_df = pd.DataFrame({'Start date': all_dates})\n",
    "\n",
    "# Adicionar colunas com valores 0\n",
    "#all_dates_df['Stop date'] = all_dates_df['Start date']\n",
    "#all_dates_df['Duration (min)'] = 0\n",
    "#all_dates_df['Total Energy (kWh)'] = 0\n",
    "#all_dates_df['Nº cartão EVIO'] = 0\n",
    "#all_dates_df['Weekday'] = all_dates_df['Start date'].dt.weekday + 1\n",
    "\n",
    "\n",
    "#all_dates_df['Start date'] = pd.to_datetime(User['Start date'])\n",
    "\n",
    "# Converter colunas de datas para datetime\n",
    "User['Start date'] = pd.to_datetime(User['Start date'])\n",
    "User['Stop date'] = pd.to_datetime(User['Stop date'])\n",
    "\n",
    "\n",
    "#print(all_dates_df, User)\n",
    "\n",
    "# Ordenar os DataFrames\n",
    "#User = User.sort_values(by='Start date').reset_index(drop=True)\n",
    "#all_dates_df = all_dates_df.sort_values(by='Start date').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Mesclar os dois DataFrames\n",
    "merged_df = pd.merge(all_dates_df, User, on='Start date', how='left')\n",
    "#merged_df = pd.merge(all_dates_df, User, on='Stop date', how='left')\n",
    "#merged_df = pd.merge(all_dates_df, User, on='Weekday', how='left')\n",
    "\n",
    "\n",
    "#print(merged_df)\n",
    "\n",
    "# Preencher NaNs com 0 para colunas específicas\n",
    "\n",
    "merged_df['Stop date'] = merged_df['Stop date'].fillna(merged_df['Start date'])\n",
    "merged_df['Duration (min)'] = merged_df['Duration (min)'].fillna(0)\n",
    "merged_df['Total Energy (kWh)'] = merged_df['Total Energy (kWh)'].fillna(0)\n",
    "merged_df['Nº cartão EVIO'] = merged_df['Nº cartão EVIO'].fillna(0)\n",
    "#merged_df['Weekday'] = merged_df['Weekday'].fillna(0)\n",
    "merged_df['Weekday'] = merged_df['Start date'].dt.day_name()\n",
    "\n",
    "weekday_mapping = {\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "\n",
    "merged_df['Weekday'] = merged_df['Weekday'].map(weekday_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Ordenar por data\n",
    "#merged_df = merged_df.sort_values('Start date').reset_index(drop=True)\n",
    "\n",
    "# Exibir resultado final\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b4a5000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Start date Stop date_x  Duration (min)_x  Total Energy (kWh)_x  \\\n",
      "0   2023-03-29  2023-03-29           111.117                 12.60   \n",
      "1   2023-03-30         NaT               NaN                   NaN   \n",
      "2   2023-03-31  2023-03-31           288.500                 48.17   \n",
      "3   2023-03-31  2023-03-31           288.500                 48.17   \n",
      "4   2023-03-31  2023-03-31           288.500                 48.17   \n",
      "..         ...         ...               ...                   ...   \n",
      "361 2024-02-21         NaT               NaN                   NaN   \n",
      "362 2024-02-22         NaT               NaN                   NaN   \n",
      "363 2024-02-23  2024-02-23           174.000                 31.10   \n",
      "364 2024-02-24         NaT               NaN                   NaN   \n",
      "365 2024-02-25  2024-02-25            16.500                 28.52   \n",
      "\n",
      "    Nº cartão EVIO_x  Weekday_x Stop date_y  Duration (min)_y  \\\n",
      "0                  0        3.0  2023-03-29           111.117   \n",
      "1                NaN        NaN         NaT               NaN   \n",
      "2                  0        5.0  2023-03-31           288.500   \n",
      "3                  0        5.0  2023-03-31           105.350   \n",
      "4                  0        5.0  2023-03-31             8.283   \n",
      "..               ...        ...         ...               ...   \n",
      "361              NaN        NaN         NaT               NaN   \n",
      "362              NaN        NaN         NaT               NaN   \n",
      "363                0        5.0  2024-02-23           174.000   \n",
      "364              NaN        NaN         NaT               NaN   \n",
      "365                0        7.0  2024-02-25            16.500   \n",
      "\n",
      "     Total Energy (kWh)_y Nº cartão EVIO_y  Weekday_y  \n",
      "0                   12.60                0        3.0  \n",
      "1                     NaN              NaN        NaN  \n",
      "2                   48.17                0        5.0  \n",
      "3                   12.26                0        5.0  \n",
      "4                    1.23                0        5.0  \n",
      "..                    ...              ...        ...  \n",
      "361                   NaN              NaN        NaN  \n",
      "362                   NaN              NaN        NaN  \n",
      "363                 31.10                0        5.0  \n",
      "364                   NaN              NaN        NaN  \n",
      "365                 28.52                0        7.0  \n",
      "\n",
      "[366 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertendo as colunas de data para o formato de data especificado\n",
    "User['Start date'] = pd.to_datetime(User['Start date'], format='%m/%d/%Y | %H:%M')\n",
    "User['Stop date'] = pd.to_datetime(User['Stop date'], format='%m/%d/%Y | %H:%M')\n",
    "\n",
    "merged_df2 = pd.merge(merged_df, User, on='Start date', how='left')\n",
    "\n",
    "print(merged_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd51a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Start date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Start date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3844\\53310727.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Preencher as colunas com valores binários (1 ou 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mUser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mstart_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Start date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mstop_hour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Stop date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhour\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Start date'"
     ]
    }
   ],
   "source": [
    "# Criar colunas para cada hora do dia (8h às 20h)\n",
    "hours = range(8, 21)\n",
    "for hour in hours:\n",
    "    User[f'Charging_{hour}h'] = 0\n",
    "\n",
    "# Preencher as colunas com valores binários (1 ou 0)\n",
    "for index, row in User.iterrows():\n",
    "    start_hour = row['Start date'].hour\n",
    "    stop_hour = row['Stop date'].hour\n",
    "    for hour in range(8, 21):\n",
    "        if hour >= start_hour and hour <= stop_hour:\n",
    "            User.at[index, f'Charging_{hour}h'] = 1\n",
    "\n",
    "# Ordenar o dataframe pela coluna 'Start date' para garantir que os dados estejam em ordem temporal\n",
    "User.sort_values(by='Start date', inplace=True)\n",
    "\n",
    "# Calcular a diferença entre o stop date do último carregamento e o start date da linha seguinte em dias\n",
    "User['Days_since_last_charge'] = (User['Start date'] - User['Stop date'].shift(1)).dt.days\n",
    "User['Days_since_last_charge'].fillna(0, inplace=True)\n",
    "\n",
    "# Calcular a diferença entre o 'Start date' da linha atual e o 'Stop date' da linha anterior em horas\n",
    "User['Hours_since_last_charge'] = (User['Start date'] - User['Stop date'].shift(1)).dt.total_seconds() / 3600\n",
    "User['Hours_since_last_charge'].fillna(0, inplace=True)\n",
    "\n",
    "# Gerando um índice de datas para o intervalo específico\n",
    "start_date = \"2023-03-29\"\n",
    "end_date = \"2024-02-25\"\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "full_dates_df = pd.DataFrame(date_range, columns=['Date'])\n",
    "\n",
    "# Converter a coluna 'Start date' do User para o mesmo formato de data\n",
    "User['Date'] = User['Start date'].dt.normalize()\n",
    "\n",
    "# Unir este índice ao dataset existente\n",
    "full_dataset = full_dates_df.merge(User, on='Date', how='left')\n",
    "\n",
    "# Preencher campos com zero para dias sem carregamento\n",
    "columns_to_fill = ['Duration (min)', 'Total Energy (kWh)', 'Weekday', 'Charging_8h', 'Charging_9h', \n",
    "                   'Charging_10h', 'Charging_11h', 'Charging_12h', 'Charging_13h', 'Charging_14h', \n",
    "                   'Charging_15h', 'Charging_16h', 'Charging_17h', 'Charging_18h', 'Charging_19h', \n",
    "                   'Charging_20h', 'Days_since_last_charge', 'Hours_since_last_charge']\n",
    "\n",
    "full_dataset[columns_to_fill] = full_dataset[columns_to_fill].fillna(0)\n",
    "\n",
    "# Corrigir a coluna Weekday\n",
    "full_dataset['Weekday'] = full_dataset['Date'].dt.day_name().map(weekday_mapping)\n",
    "\n",
    "# Preencher as colunas 'Days_since_last_charge' e 'Hours_since_last_charge' corretamente\n",
    "for i in range(1, len(full_dataset)):\n",
    "    if full_dataset.loc[i, 'Total Energy (kWh)'] == 0:\n",
    "        full_dataset.loc[i, 'Days_since_last_charge'] = full_dataset.loc[i-1, 'Days_since_last_charge'] + 1\n",
    "        full_dataset.loc[i, 'Hours_since_last_charge'] = full_dataset.loc[i-1, 'Hours_since_last_charge'] + 24\n",
    "    else:\n",
    "        full_dataset.loc[i, 'Days_since_last_charge'] = 0\n",
    "        full_dataset.loc[i, 'Hours_since_last_charge'] = 0\n",
    "\n",
    "# Verificar se há pelo menos dois valores diferentes em cada coluna de destino\n",
    "for hour in hours:\n",
    "    col_name = f'Charging_{hour}h'\n",
    "    if full_dataset[col_name].nunique() < 2:\n",
    "        print(f\"A coluna {col_name} não contém pelo menos duas classes distintas. Removendo esta coluna.\")\n",
    "        full_dataset.drop(columns=[col_name], inplace=True)\n",
    "\n",
    "# Verificar se ainda temos colunas de destino após a remoção\n",
    "target_columns = [f'Charging_{hour}h' for hour in hours if f'Charging_{hour}h' in full_dataset.columns]\n",
    "if not target_columns:\n",
    "    raise ValueError(\"Não há colunas de destino com pelo menos duas classes distintas. Não é possível treinar o modelo.\")\n",
    "    \n",
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114d515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3edf1416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Total Energy (kWh)\n",
      "0    2023-03-29               12.60\n",
      "1    2023-03-31               61.66\n",
      "2    2023-04-03               43.80\n",
      "3    2023-04-05               51.27\n",
      "4    2023-04-06               29.33\n",
      "..          ...                 ...\n",
      "107  2024-02-11               22.06\n",
      "108  2024-02-19               35.26\n",
      "109  2024-02-20               27.23\n",
      "110  2024-02-23               31.10\n",
      "111  2024-02-25               28.52\n",
      "\n",
      "[112 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Criando uma nova coluna 'Date' que contém apenas a data (sem a hora)\n",
    "User['Date'] = User['Start date'].dt.date\n",
    "\n",
    "# Convertendo os valores de energia para o formato numérico adequado\n",
    "#User['Total Energy (kWh)'] = User['Total Energy (kWh)'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Agrupando os dados pela coluna 'Date' e somando os valores de 'Total Energy (kWh)'\n",
    "User = User.groupby('Date')['Total Energy (kWh)'].sum().reset_index()\n",
    "\n",
    "print(User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f578728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Total Energy (kWh)\n",
      "0   2023-03-29               12.60\n",
      "1   2023-03-30                0.00\n",
      "2   2023-03-31               61.66\n",
      "3   2023-04-01                0.00\n",
      "4   2023-04-02                0.00\n",
      "..         ...                 ...\n",
      "329 2024-02-21                0.00\n",
      "330 2024-02-22                0.00\n",
      "331 2024-02-23               31.10\n",
      "332 2024-02-24                0.00\n",
      "333 2024-02-25               28.52\n",
      "\n",
      "[334 rows x 2 columns]\n",
      "          Date  Total Energy (kWh)\n",
      "0   2023-03-29               12.60\n",
      "1   2023-03-30                0.00\n",
      "2   2023-03-31               61.66\n",
      "3   2023-04-01                0.00\n",
      "4   2023-04-02                0.00\n",
      "..         ...                 ...\n",
      "329 2024-02-21                0.00\n",
      "330 2024-02-22                0.00\n",
      "331 2024-02-23               31.10\n",
      "332 2024-02-24                0.00\n",
      "333 2024-02-25               28.52\n",
      "\n",
      "[334 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Criando um intervalo de datas que cubra todo o período de interesse\n",
    "date_range = pd.date_range(start=User['Date'].min(), end=User['Date'].max(), freq='D')\n",
    "\n",
    "# Criando um DataFrame com o intervalo de datas\n",
    "date_df = pd.DataFrame({'Date': date_range})\n",
    "\n",
    "# Renomeando a coluna 'Date' para 'Date_new'\n",
    "date_df.rename(columns={'Date': 'Date_new'}, inplace=True)\n",
    "\n",
    "# Convertendo a coluna 'Date' em 'daily_energy_sum' para datetime\n",
    "User['Date'] = pd.to_datetime(User['Date'])\n",
    "\n",
    "# Mesclando os DataFrames usando merge\n",
    "merged_df = pd.merge(date_df, User, left_on='Date_new', right_on='Date', how='left')\n",
    "\n",
    "# Preenchendo os valores ausentes na coluna 'Total Energy (kWh)' com zero\n",
    "merged_df['Total Energy (kWh)'].fillna(0, inplace=True)\n",
    "merged_df = merged_df.drop(columns=['Date'])\n",
    "merged_df.rename(columns={'Date_new': 'Date'}, inplace=True)\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "User = merged_df\n",
    "merged_df.rename(columns={'Date': 'Date'}, inplace=True)\n",
    "print(User)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb6ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
